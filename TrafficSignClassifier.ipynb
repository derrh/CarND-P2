{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Traffic Sign Classifier\n",
    "\n",
    "By Derrick Hathaway\n",
    "<br/>November 11, 2017\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "We will be training a model to classify traffice signs from the German [Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "We will start by loading our data set which has been subdivided into three subsets: a training set which will be used to train the model, a validation set that we will use to validate the progress of our training, and a test set. Once training is complete we will use the test set to determine the accuracy of our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file = 'valid.p'\n",
    "test_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(test_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "X_train_in, y_train = train['features'], train['labels'].astype(np.uint8)\n",
    "X_valid_in, y_valid = valid['features'], valid['labels'].astype(np.uint8)\n",
    "X_test_in, y_test = test['features'], test['labels'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "Below is a random sample from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "sign_names = []\n",
    "with open('samples/signnames.csv', 'r') as f:\n",
    "    data = list(csv.reader(f))\n",
    "    for i, sign_name in data:\n",
    "        sign_names.append(sign_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Turn right ahead\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYkiCEcSQBCOIIQlGEEMSjPAX5NMkMr94PlkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c1c066080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train_in))\n",
    "image = X_train_in[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "print(\"Label\", sign_names[y_train[index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "In order to improve training performance, we will take certain steps to condition the input data. The first step is to adjust the input data so that the range for each pixel is `(-1.0, 1.0]`.\n",
    "\n",
    "Next we will shuffle the training data so that the features and labels are encountered by the optimizer in a random order. If the input data are ordered, this can make it difficult for our network to converge on an acceptable solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust(x):\n",
    "    return (x.astype(np.float32) - 128) / 128\n",
    "\n",
    "X_train = adjust(X_train_in)\n",
    "X_valid = adjust(X_valid_in)\n",
    "X_test = adjust(X_test_in)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters\n",
    "\n",
    "These are a few of the levers we can turn to adjust the training performance. These include the batch size, the number of epochs, the dropout rate used during training, the mean and standard deviation of our initial random weights, and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "dropout = 0.50\n",
    "\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "I've created some helper functions to help make the structure of my model more readable. This was very useful during development because it allowed me to adjust the size of the layers and make other changes with confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def weights(shape):\n",
    "    return tf.truncated_normal(shape=shape, mean=mu, stddev=sigma)\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(\n",
    "        x,\n",
    "        W,\n",
    "        strides=[1, strides, strides, 1],\n",
    "        padding='VALID')\n",
    "    \n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LeNet Model\n",
    "\n",
    "I used the LeNet-5 model from the CNN Lesson as a starting point. I found that increasing the k-size of the convolution layers, as well as the size of the fully connected layers improved training performance significantly. The road sign images are more complex than black and white handwrittend digits so more depth in the convolutional layers is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "weights = {\n",
    "    'conv0': tf.Variable(weights([5,5,3,24])),\n",
    "    'conv1': tf.Variable(weights([5,5,24,64])),\n",
    "    'fc1': tf.Variable(weights([1600, 600])),\n",
    "    'fc2': tf.Variable(weights([600, 200])),\n",
    "    'fc3': tf.Variable(weights([200, 43])),\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'conv0': tf.Variable(tf.zeros(24)),\n",
    "    'conv1': tf.Variable(tf.zeros(64)),\n",
    "    'fc1': tf.Variable(tf.zeros(600)),\n",
    "    'fc2': tf.Variable(tf.zeros(200)),\n",
    "    'fc3': tf.Variable(tf.zeros(43)),\n",
    "}\n",
    "\n",
    "def LeNet(x, dropout):\n",
    "    conv_0 = conv2d(x, weights['conv0'], bias['conv0'])\n",
    "    conv_0 = maxpool2d(conv_0)\n",
    "    \n",
    "    conv_1 = conv2d(conv_0, weights['conv1'], bias['conv1'])\n",
    "    conv_1 = maxpool2d(conv_1)\n",
    "    \n",
    "    flat = flatten(conv_1)\n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(flat, weights['fc1']), bias['fc1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['fc2']), bias['fc2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    fc3 = tf.add(tf.matmul(fc2, weights['fc3']), bias['fc3'])\n",
    "    \n",
    "    return fc3\n",
    "\n",
    "# signs dataset consists of 32x32x3 images\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "# Classify over 43 road signs labeled 0-42\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = LeNet(x, keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,logits=logits)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learn_rate)\n",
    "train_op = opt.minimize(loss_op)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 ...\n",
      "Validation loss = 0.581\n",
      "Validation accuracy = 0.838\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation loss = 0.283\n",
      "Validation accuracy = 0.919\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation loss = 0.266\n",
      "Validation accuracy = 0.932\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation loss = 0.203\n",
      "Validation accuracy = 0.944\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation loss = 0.189\n",
      "Validation accuracy = 0.947\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation loss = 0.218\n",
      "Validation accuracy = 0.941\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation loss = 0.244\n",
      "Validation accuracy = 0.940\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation loss = 0.230\n",
      "Validation accuracy = 0.949\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation loss = 0.204\n",
      "Validation accuracy = 0.953\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation loss = 0.187\n",
      "Validation accuracy = 0.953\n",
      "\n",
      "Test loss = 0.260\n",
      "Test accuracy = 0.947\n"
     ]
    }
   ],
   "source": [
    "def eval_data(X_data, y_data):\n",
    "    \"\"\"\n",
    "    Given a dataset as input returns the loss and accuracy.\n",
    "    \"\"\"\n",
    "    num_examples = len(y_data)\n",
    "    total_acc, total_loss = 0, 0\n",
    "    sess = tf.get_default_session()\n",
    "    for batch in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x = X_data[batch:batch + BATCH_SIZE]\n",
    "        batch_y = y_data[batch:batch + BATCH_SIZE]\n",
    "        loss, acc = sess.run([loss_op, accuracy_op], feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        total_acc += (acc * batch_x.shape[0])\n",
    "        total_loss += (loss * batch_x.shape[0])\n",
    "    return total_loss/num_examples, total_acc/num_examples\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_file = './train_model.ckpt'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(y_train)\n",
    "\n",
    "    # Train model\n",
    "    for i in range(EPOCHS):\n",
    "        for batch in range(0, num_examples, BATCH_SIZE):\n",
    "            batch_x = X_train[batch:batch+BATCH_SIZE]\n",
    "            batch_y = y_train[batch:batch+BATCH_SIZE]\n",
    "            loss = sess.run(train_op, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "        val_loss, val_acc = eval_data(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation loss = {:.3f}\".format(val_loss))\n",
    "        print(\"Validation accuracy = {:.3f}\".format(val_acc))\n",
    "        print()\n",
    "\n",
    "    # Evaluate on the test data\n",
    "    test_loss, test_acc = eval_data(X_test, y_test)\n",
    "    print(\"Test loss = {:.3f}\".format(test_loss))\n",
    "    print(\"Test accuracy = {:.3f}\".format(test_acc))\n",
    "    \n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing Against New Images\n",
    "\n",
    "I have found a few images from the web of various German traffic signs. We will use the trained model to classify these signs. I have cropped and resized the images to match the expected input of the network.\n",
    "\n",
    "| Image                                        | Name       |\n",
    "| -------------------------------------------- | ---------- |\n",
    "| ![stop](samples/stop.png \"Stop\")             | Stop       |\n",
    "| ![stop](samples/yield.png \"Yield\")           | Yield      |\n",
    "| ![stop](samples/prohibited.png \"Prohibited\") | Prohibited |\n",
    "| ![stop](samples/nopassing.png \"No Passing\")  | No Passing |\n",
    "| ![stop](samples/direction.png \"Direction\")   | Direction  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| ![filename](samples/nopassing.png 'file') Sign Classification | Probability |\n",
       "| ------------------------------ | ----------- |\n",
       "| No passing | 1.00 |\n",
       "| Go straight or left | 0.00 |\n",
       "| End of no passing | 0.00 |\n",
       "| Dangerous curve to the left | 0.00 |\n",
       "| No passing for vehicles over 3.5 metric tons | 0.00 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| ![filename](samples/stop.png 'file') Sign Classification | Probability |\n",
       "| ------------------------------ | ----------- |\n",
       "| Priority road | 1.00 |\n",
       "| End of all speed and passing limits | 0.00 |\n",
       "| Stop | 0.00 |\n",
       "| No entry | 0.00 |\n",
       "| No passing for vehicles over 3.5 metric tons | 0.00 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure why the stop sign classification failed. I suspect converting the images to a different color space would have helped with this classification.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| ![filename](samples/yield.png 'file') Sign Classification | Probability |\n",
       "| ------------------------------ | ----------- |\n",
       "| Yield | 1.00 |\n",
       "| No passing for vehicles over 3.5 metric tons | 0.00 |\n",
       "| No passing | 0.00 |\n",
       "| Ahead only | 0.00 |\n",
       "| Speed limit (60km/h) | 0.00 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| ![filename](samples/direction.png 'file') Sign Classification | Probability |\n",
       "| ------------------------------ | ----------- |\n",
       "| Keep right | 1.00 |\n",
       "| Go straight or right | 0.00 |\n",
       "| Roundabout mandatory | 0.00 |\n",
       "| Turn left ahead | 0.00 |\n",
       "| Priority road | 0.00 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| ![filename](samples/prohibited.png 'file') Sign Classification | Probability |\n",
       "| ------------------------------ | ----------- |\n",
       "| Priority road | 0.54 |\n",
       "| No passing for vehicles over 3.5 metric tons | 0.21 |\n",
       "| Speed limit (30km/h) | 0.17 |\n",
       "| Yield | 0.05 |\n",
       "| Road work | 0.01 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "top_k = tf.nn.top_k(tf.nn.softmax(logits), k=5)\n",
    "\n",
    "def classify_image(filename):\n",
    "    file = mpimg.imread(filename)\n",
    "    file = file[:,:,:3]\n",
    "    file = np.expand_dims(file, axis=0)\n",
    "    sess = tf.get_default_session()\n",
    "    result = sess.run(top_k, feed_dict={x: file, keep_prob: 1.0})\n",
    "    output = \"\"\"\n",
    "| ![filename]({} 'file') Sign Classification | Probability |\n",
    "| ------------------------------ | ----------- |\n",
    "\"\"\"\n",
    "    for i in range(len(result.values[0])):\n",
    "        output += \"| {} | {:.2f} |\\n\".format(\n",
    "            sign_names[result.indices[0][i]],\n",
    "            result.values[0][i]\n",
    "        )\n",
    "    display(Markdown(output.format(filename)))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    classify_image('samples/nopassing.png')\n",
    "    \n",
    "    classify_image('samples/stop.png')\n",
    "    print(\"I'm not sure why the stop sign classification failed. I suspect converting the images to a different color space would have helped with this classification.\")\n",
    "    print(\"\")\n",
    "    \n",
    "    classify_image('samples/yield.png')\n",
    "    classify_image('samples/direction.png')\n",
    "    classify_image('samples/prohibited.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For my \"real world\" tests the model performed at 60% efficiency. This is less that I would have expected. In hindsight using a different color space would likely have yielded better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
